{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e57e5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import itertools as it\n",
    "import datetime as dt\n",
    "from dateutil import parser as dtparser\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "import csv\n",
    "import echopype as ep\n",
    "import os\n",
    "import warnings\n",
    "from echopype import open_raw\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from dateutil import parser as dtparser\n",
    "from importlib.metadata import version\n",
    "from urllib.parse import urljoin\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "fs = fsspec.filesystem('https')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d99b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "version('echopype')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661349b",
   "metadata": {},
   "source": [
    "\n",
    "Making Data folder in current working directory to store files. Please note this folder won't be pushed on github as it's included in .gitignore.\n",
    "From now on the code will use 'current_directory' variable for accessing the files, and 'data_folder' for accessing data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd006d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define the relative path to the \"data\" folder\n",
    "data_folder = os.path.join(current_directory, 'data')\n",
    "\n",
    "# If the \"data\" folder doesn't exist, create it\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68173b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ooi_raw_url = \"https://rawdata.oceanobservatories.org/files/CE04OSPS/PC01B/ZPLSCB102_10.33.10.143/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(raw_file: str, start: datetime, end: datetime) -> bool:\n",
    "    ## Check if file url is in datetime range\n",
    "    file_name = Path(raw_file).name\n",
    "    print('File Name:', file_name)\n",
    "    \n",
    "    if 'OOI-' in file_name:\n",
    "        format_string = \"OOI-D%Y%m%d-T%H%M%S.raw\"\n",
    "        file_datetime = datetime.strptime(file_name, format_string)\n",
    "        print('Parsed Datetime:', file_datetime)\n",
    "        return start <= file_datetime <= end\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39df392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = dt.datetime(2016, 8, 21, 0, 0)\n",
    "end_datetime = dt.datetime(2016, 8, 22, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5447f-1e32-43db-aabb-cc6471a96216",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_day_urls = []\n",
    "current_date = start_datetime\n",
    "\n",
    "while current_date <= end_datetime:\n",
    "    day_url = urljoin(\n",
    "        ooi_raw_url,\n",
    "        f\"{current_date.year}/{current_date.month:02d}/{current_date.day:02d}\"\n",
    "    )\n",
    "    desired_day_urls.append(day_url)\n",
    "    current_date += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_raw_file_urls = it.chain.from_iterable([fs.glob(f\"{day_url}/*.raw\") for day_url in desired_day_urls])\n",
    "all_raw_file_urls = it.chain.from_iterable([fs.glob(f\"{day_url}/*.raw\") for day_url in desired_day_urls if  requests.get(day_url).status_code ==200 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6cc99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desired_raw_file_urls = list(filter(\n",
    "    lambda raw_file: in_range(\n",
    "        raw_file,\n",
    "        start_datetime-dt.timedelta(hours=0),  # 3 hour buffer to select files\n",
    "        end_datetime+dt.timedelta(hours=0)\n",
    "    ),\n",
    "    all_raw_file_urls\n",
    "))\n",
    "print(f\"There are {len(desired_raw_file_urls)} raw files within the specified datetime range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(desired_raw_file_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8631a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating new CSV file for storing raw files urls\n",
    "\n",
    "csv_file_path =  os.path.join(data_folder, 'raw_files.csv')\n",
    "\n",
    "# Create an empty CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write an empty row to the CSV file (optional)\n",
    "    csv_writer.writerow([])\n",
    "\n",
    "print(f\"Empty CSV file created at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(desired_raw_file_urls).to_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80762652",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_raw_file_urls = pd.read_csv(csv_file_path)\n",
    "desired_raw_file_urls.drop(['Unnamed: 0'], axis =1 , inplace=True)\n",
    "desired_raw_file_urls = list(desired_raw_file_urls['0'])\n",
    "desired_raw_file_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def process_raw_file(raw_file_url, output_dpath):\n",
    "    try:\n",
    "        print(f\"Processing: {raw_file_url}\")\n",
    "        ed = ep.open_raw(raw_file=raw_file_url, sonar_model='ek60', use_swap=True)\n",
    "        ed.to_zarr(save_path=data_folder, overwrite=True)\n",
    "        print(f\"Completed processing: {raw_file_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {raw_file_url}: {e}\")\n",
    "\n",
    "\n",
    "# Create Dask delayed objects for processing each raw file\n",
    "delayed_processing = [dask.delayed(process_raw_file)(raw_file_url, data_folder) for raw_file_url in tqdm(desired_raw_file_urls)]\n",
    "\n",
    "# Trigger Dask computations\n",
    "dask.compute(*delayed_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d722b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e14831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output_dpath = Path(data_folder)\n",
    "from pathlib import Path\n",
    "data_folder_path = Path(data_folder)  # Convert the string to a Path object\n",
    "\n",
    "print(data_folder_path)\n",
    "ed_list = []\n",
    "for converted_file in sorted(data_folder_path.glob(\"*.zarr\")):\n",
    "    print(converted_file)\n",
    "    ed_list.append(ep.open_converted(converted_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = ep.combine_echodata(ed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_Sv = ep.calibrate.compute_Sv(ed).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb501e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_Sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231fea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
